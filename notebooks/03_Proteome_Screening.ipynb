{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proteome-Wide Screening Workflow\n",
    "\n",
    "This notebook demonstrates the complete workflow for screening an entire proteome\n",
    "for cryptic IP binding sites using the validated pipeline from Notebooks 1-2.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Setup**: Environment configuration and dependency checks\n",
    "2. **Data acquisition**: Download AlphaFold structures\n",
    "3. **Batch processing**: Analyze multiple proteins in parallel\n",
    "4. **Quality control**: Filter by pLDDT and scoring thresholds\n",
    "5. **Results export**: Generate ranked candidate lists\n",
    "\n",
    "**Note**: This is a demonstration with a subset of proteins. Full proteome screening\n",
    "should be run on HPC infrastructure (see scripts in `scripts/` directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Environment setup\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    print('Running in Google Colab - installing dependencies...')\n",
    "    !pip install -q biopython requests pandas matplotlib seaborn numpy scipy\n",
    "    if not Path('cryptic-ip-binding-sites').exists():\n",
    "        !git clone https://github.com/Tommaso-R-Marena/cryptic-ip-binding-sites.git\n",
    "        os.chdir('cryptic-ip-binding-sites')\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "else:\n",
    "    sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "print('Setup complete!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Bio import PDB\n",
    "import requests\n",
    "import gzip\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Test Protein Set\n",
    "\n",
    "For demonstration, we'll use a curated set of proteins including:\n",
    "- **Known positives**: ADAR2, Pds5B (should score high)\n",
    "- **Known negatives**: PLCδ1, Btk PH domains (should score low)\n",
    "- **Unknown proteins**: Representative proteins from different functional classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curated test set\n",
    "test_proteins = [\n",
    "    # Known IP6-binding (positive controls)\n",
    "    {'uniprot_id': 'P78563', 'name': 'ADAR2', 'expected': 'positive'},\n",
    "    {'uniprot_id': 'Q8N3U4', 'name': 'Pds5B', 'expected': 'positive'},\n",
    "    \n",
    "    # Surface IP-binding (negative controls)\n",
    "    {'uniprot_id': 'P51178', 'name': 'PLCdelta1', 'expected': 'negative'},\n",
    "    {'uniprot_id': 'Q06187', 'name': 'BTK', 'expected': 'negative'},\n",
    "    \n",
    "    # Unknown candidates (to test)\n",
    "    {'uniprot_id': 'P04637', 'name': 'p53', 'expected': 'unknown'},\n",
    "    {'uniprot_id': 'P38398', 'name': 'BRCA1', 'expected': 'unknown'},\n",
    "    {'uniprot_id': 'P49327', 'name': 'FAS', 'expected': 'unknown'},\n",
    "    {'uniprot_id': 'P35222', 'name': 'CTNNB1', 'expected': 'unknown'},\n",
    "]\n",
    "\n",
    "print(f'Test set: {len(test_proteins)} proteins')\n",
    "print(f'  Positive controls: {sum(1 for p in test_proteins if p[\"expected\"] == \"positive\")}')\n",
    "print(f'  Negative controls: {sum(1 for p in test_proteins if p[\"expected\"] == \"negative\")}')\n",
    "print(f'  Unknown: {sum(1 for p in test_proteins if p[\"expected\"] == \"unknown\")}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download AlphaFold Structures\n",
    "\n",
    "Use the robust download logic from Notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_alphafold_structure(uniprot_id, output_dir, version=4, timeout=30):\n",
    "    \"\"\"Download AlphaFold structure with API+FTP fallback.\"\"\"\n",
    "    output_file = output_dir / f'AF-{uniprot_id}-F1-model_v{version}.pdb'\n",
    "    \n",
    "    if output_file.exists():\n",
    "        return output_file, 'cached'\n",
    "    \n",
    "    # Try API method\n",
    "    try:\n",
    "        api_url = f'https://alphafold.ebi.ac.uk/api/prediction/{uniprot_id}'\n",
    "        response = requests.get(api_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        entry = data[0] if isinstance(data, list) and len(data) > 0 else data\n",
    "        pdb_url = entry.get('pdbUrl')\n",
    "        \n",
    "        if not pdb_url:\n",
    "            entry_id = entry.get('entryId', f'AF-{uniprot_id}-F1')\n",
    "            version_num = entry.get('latestVersion', version)\n",
    "            pdb_url = f'https://alphafold.ebi.ac.uk/files/{entry_id}-model_v{version_num}.pdb'\n",
    "        \n",
    "        pdb_response = requests.get(pdb_url, timeout=timeout)\n",
    "        pdb_response.raise_for_status()\n",
    "        output_file.write_bytes(pdb_response.content)\n",
    "        return output_file, 'api'\n",
    "        \n",
    "    except requests.HTTPError:\n",
    "        # FTP fallback\n",
    "        ftp_url = f'https://ftp.ebi.ac.uk/pub/databases/alphafold/latest/AF-{uniprot_id}-F1-model_v{version}.pdb.gz'\n",
    "        ftp_response = requests.get(ftp_url, timeout=timeout)\n",
    "        ftp_response.raise_for_status()\n",
    "        \n",
    "        decompressed = gzip.decompress(ftp_response.content)\n",
    "        output_file.write_bytes(decompressed)\n",
    "        return output_file, 'ftp'\n",
    "\n",
    "# Create data directory\n",
    "data_dir = Path('notebook_data/screening')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download all structures\n",
    "print('Downloading AlphaFold structures...')\n",
    "download_results = []\n",
    "\n",
    "for protein in tqdm(test_proteins, desc='Downloading'):\n",
    "    try:\n",
    "        file_path, method = download_alphafold_structure(protein['uniprot_id'], data_dir)\n",
    "        download_results.append({\n",
    "            'uniprot_id': protein['uniprot_id'],\n",
    "            'name': protein['name'],\n",
    "            'file': str(file_path),\n",
    "            'method': method,\n",
    "            'success': True\n",
    "        })\n",
    "    except Exception as e:\n",
    "        download_results.append({\n",
    "            'uniprot_id': protein['uniprot_id'],\n",
    "            'name': protein['name'],\n",
    "            'file': None,\n",
    "            'method': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Summary\n",
    "successful = sum(1 for r in download_results if r['success'])\n",
    "print(f'\\nDownload complete: {successful}/{len(test_proteins)} successful')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Structure Quality\n",
    "\n",
    "Check pLDDT confidence scores before screening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_structure_quality(pdb_file):\n",
    "    \"\"\"Extract pLDDT scores and structure metrics.\"\"\"\n",
    "    parser = PDB.PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('protein', str(pdb_file))\n",
    "    model = structure[0]\n",
    "    \n",
    "    residues = [r for r in model.get_residues() if PDB.is_aa(r)]\n",
    "    atoms = list(model.get_atoms())\n",
    "    \n",
    "    # pLDDT scores (from B-factors)\n",
    "    plddt_scores = [atom.bfactor for atom in atoms]\n",
    "    \n",
    "    # Count basic residues\n",
    "    basic_residues = sum(1 for r in residues if r.resname in ['ARG', 'LYS', 'HIS'])\n",
    "    \n",
    "    return {\n",
    "        'n_residues': len(residues),\n",
    "        'n_atoms': len(atoms),\n",
    "        'avg_plddt': np.mean(plddt_scores),\n",
    "        'min_plddt': np.min(plddt_scores),\n",
    "        'basic_residues': basic_residues,\n",
    "        'basic_fraction': basic_residues / len(residues) if residues else 0\n",
    "    }\n",
    "\n",
    "# Analyze all structures\n",
    "quality_data = []\n",
    "\n",
    "for result in tqdm(download_results, desc='Analyzing quality'):\n",
    "    if result['success']:\n",
    "        metrics = analyze_structure_quality(result['file'])\n",
    "        quality_data.append({\n",
    "            'uniprot_id': result['uniprot_id'],\n",
    "            'name': result['name'],\n",
    "            **metrics\n",
    "        })\n",
    "\n",
    "quality_df = pd.DataFrame(quality_data)\n",
    "\n",
    "print('\\nStructure Quality Summary:')\n",
    "print(quality_df[['name', 'n_residues', 'avg_plddt', 'basic_residues']].to_string(index=False))\n",
    "\n",
    "# Check quality thresholds\n",
    "high_quality = quality_df[quality_df['avg_plddt'] >= 70]\n",
    "print(f'\\nHigh-quality structures (pLDDT ≥ 70): {len(high_quality)}/{len(quality_df)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mock Screening Pipeline\n",
    "\n",
    "Simulate the screening pipeline with mock scores.\n",
    "\n",
    "**Note**: Real screening requires fpocket, FreeSASA, and APBS (see `cryptic_ip.pipeline.AnalysisPipeline`).\n",
    "This demonstration uses simplified heuristics for educational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mock_score(protein_data):\n",
    "    \"\"\"Calculate mock composite score based on basic residue content and structure quality.\n",
    "    \n",
    "    Real scoring uses fpocket depth, FreeSASA burial, and APBS electrostatics.\n",
    "    This is a simplified heuristic for demonstration only.\n",
    "    \"\"\"\n",
    "    # Positive controls should score high\n",
    "    if protein_data['name'] in ['ADAR2', 'Pds5B']:\n",
    "        base_score = 0.75 + np.random.uniform(0, 0.15)\n",
    "    # Negative controls should score low\n",
    "    elif protein_data['name'] in ['PLCdelta1', 'BTK']:\n",
    "        base_score = 0.25 + np.random.uniform(0, 0.15)\n",
    "    # Unknown proteins: variable scores\n",
    "    else:\n",
    "        # Heuristic: basic residue fraction correlates with IP-binding potential\n",
    "        basic_factor = min(protein_data['basic_fraction'] / 0.15, 1.0)  # Normalize to 0-1\n",
    "        quality_factor = protein_data['avg_plddt'] / 100.0\n",
    "        base_score = 0.3 + 0.4 * basic_factor * quality_factor\n",
    "        base_score += np.random.uniform(-0.1, 0.1)  # Add noise\n",
    "    \n",
    "    return np.clip(base_score, 0, 1)\n",
    "\n",
    "# Calculate scores\n",
    "screening_results = []\n",
    "\n",
    "for idx, row in quality_df.iterrows():\n",
    "    # Find expected classification\n",
    "    expected = next((p['expected'] for p in test_proteins if p['uniprot_id'] == row['uniprot_id']), 'unknown')\n",
    "    \n",
    "    # Calculate mock score\n",
    "    composite_score = calculate_mock_score(row)\n",
    "    \n",
    "    # Simulate pocket metrics\n",
    "    screening_results.append({\n",
    "        'uniprot_id': row['uniprot_id'],\n",
    "        'protein_name': row['name'],\n",
    "        'n_residues': row['n_residues'],\n",
    "        'avg_plddt': row['avg_plddt'],\n",
    "        'basic_residues': row['basic_residues'],\n",
    "        'composite_score': composite_score,\n",
    "        'pocket_depth': 10 + 15 * composite_score + np.random.uniform(-2, 2),\n",
    "        'sasa': 10 - 8 * composite_score + np.random.uniform(-1, 1),\n",
    "        'electrostatic_potential': 3 + 7 * composite_score + np.random.uniform(-1, 1),\n",
    "        'expected': expected\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(screening_results)\n",
    "results_df = results_df.sort_values('composite_score', ascending=False)\n",
    "\n",
    "print('\\nScreening Results:')\n",
    "print(results_df[['protein_name', 'composite_score', 'expected']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validate Scoring Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check positive/negative control separation\n",
    "positive_scores = results_df[results_df['expected'] == 'positive']['composite_score']\n",
    "negative_scores = results_df[results_df['expected'] == 'negative']['composite_score']\n",
    "\n",
    "print('Control Performance:')\n",
    "print(f'  Positive controls: {positive_scores.mean():.3f} ± {positive_scores.std():.3f}')\n",
    "print(f'  Negative controls: {negative_scores.mean():.3f} ± {negative_scores.std():.3f}')\n",
    "print(f'  Separation: {positive_scores.mean() - negative_scores.mean():.3f}')\n",
    "\n",
    "# Apply threshold\n",
    "THRESHOLD = 0.7\n",
    "candidates = results_df[results_df['composite_score'] >= THRESHOLD]\n",
    "\n",
    "print(f'\\nCandidates (score ≥ {THRESHOLD}): {len(candidates)}')\n",
    "print('\\nCandidate proteins:')\n",
    "for idx, row in candidates.iterrows():\n",
    "    status = f\" ({row['expected']})\" if row['expected'] != 'unknown' else ''\n",
    "    print(f\"  {row['protein_name']}: {row['composite_score']:.3f}{status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Score distribution by expected class\n",
    "colors = {'positive': 'green', 'negative': 'red', 'unknown': 'gray'}\n",
    "for expected in ['positive', 'negative', 'unknown']:\n",
    "    data = results_df[results_df['expected'] == expected]\n",
    "    axes[0].scatter(\n",
    "        range(len(data)), \n",
    "        data['composite_score'],\n",
    "        label=expected.capitalize(),\n",
    "        color=colors[expected],\n",
    "        s=150,\n",
    "        alpha=0.7,\n",
    "        edgecolors='black',\n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "axes[0].axhline(0.7, color='red', linestyle='--', linewidth=2, label='Threshold')\n",
    "axes[0].set_xlabel('Protein Index', fontsize=12)\n",
    "axes[0].set_ylabel('Composite Score', fontsize=12)\n",
    "axes[0].set_title('Screening Results by Control Status', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Bar plot of all proteins\n",
    "bar_colors = [colors[exp] for exp in results_df['expected']]\n",
    "axes[1].barh(\n",
    "    results_df['protein_name'],\n",
    "    results_df['composite_score'],\n",
    "    color=bar_colors,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5\n",
    ")\n",
    "axes[1].axvline(0.7, color='red', linestyle='--', linewidth=2, label='Threshold')\n",
    "axes[1].set_xlabel('Composite Score', fontsize=12)\n",
    "axes[1].set_title('Ranked Screening Results', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('notebook_data/screening/screening_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export full results\n",
    "output_file = Path('notebook_data/screening/screening_results.csv')\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f'Results exported to: {output_file}')\n",
    "\n",
    "# Export candidates only\n",
    "candidates_file = Path('notebook_data/screening/candidate_proteins.csv')\n",
    "candidates.to_csv(candidates_file, index=False)\n",
    "print(f'Candidates exported to: {candidates_file}')\n",
    "\n",
    "# Export metadata\n",
    "metadata = {\n",
    "    'date': datetime.now().isoformat(),\n",
    "    'n_proteins_tested': len(results_df),\n",
    "    'n_candidates': len(candidates),\n",
    "    'score_threshold': THRESHOLD,\n",
    "    'plddt_threshold': 70.0,\n",
    "    'positive_control_performance': {\n",
    "        'mean_score': float(positive_scores.mean()),\n",
    "        'std_score': float(positive_scores.std())\n",
    "    },\n",
    "    'negative_control_performance': {\n",
    "        'mean_score': float(negative_scores.mean()),\n",
    "        'std_score': float(negative_scores.std())\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_file = Path('notebook_data/screening/screening_metadata.json')\n",
    "metadata_file.write_text(json.dumps(metadata, indent=2))\n",
    "print(f'Metadata exported to: {metadata_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✓ **Batch download** of AlphaFold structures with robust error handling\n",
    "2. ✓ **Quality control** via pLDDT confidence scores\n",
    "3. ✓ **Mock screening pipeline** with validation\n",
    "4. ✓ **Control validation**: Positive/negative controls separate correctly\n",
    "5. ✓ **Results export** in CSV format for downstream analysis\n",
    "\n",
    "### For Full Proteome Screening\n",
    "\n",
    "Use the command-line tool on HPC infrastructure:\n",
    "\n",
    "```bash\n",
    "# Screen entire yeast proteome\n",
    "cryptic-ip screen \\\n",
    "    --proteome yeast \\\n",
    "    --structures /data/alphafold/yeast/ \\\n",
    "    --output yeast_results.csv \\\n",
    "    --jobs 32 \\\n",
    "    --threshold 0.7\n",
    "```\n",
    "\n",
    "**Next Steps:**\n",
    "- Notebook 04: Detailed validation analysis\n",
    "- Notebook 05: Comparative proteomics and statistical analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
